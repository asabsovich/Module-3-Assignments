{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 04:  More Tools for the Toolbox: Null Values, Categorical Features, and Cross Validation\n",
    "\n",
    "In this homework, we are going to add three tools to your toolbox which will be essential when you work with real datasets:\n",
    "1. What do we do with null-values?\n",
    "2. How do we deal with non-numeric features?\n",
    "3. What validation strategy provides the best estimate of the final testing score?\n",
    "\n",
    "For (1), we'll explore several ways of dealing with null values:\n",
    "- Removing columns with too many null values,\n",
    "- Imputing values for missing categorical labels using the \"most frequent\" category strategy, and\n",
    "- Imputing values for missing numeric values using the median. \n",
    "\n",
    "\n",
    "For (2), we'll use ordinal encoding to replace categorical labels with floats.\n",
    "\n",
    "For (3), we'll try three different cross-validation strategies:\n",
    "\n",
    "- 5-Fold CV,\n",
    "- Repeated 5-Fold CV, and\n",
    "- Leave One Out CV, \n",
    "\n",
    "and see which comes closest to estimating the final testing metric (RMSE and, optionally, $R^2$). \n",
    "\n",
    "\n",
    "#### Grading: There are eight (8) answers to provide, each worth 6 points.  (You get 2 points for free.)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install -q --upgrade pip\n",
    "!python -m pip install -q pandas numpy matplotlib scikit-learn tqdm kagglehub ipywidgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful imports\n",
    "\n",
    "import os\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedKFold, LeaveOneOut\n",
    "from sklearn.linear_model    import LinearRegression\n",
    "from sklearn.preprocessing   import OrdinalEncoder, OneHotEncoder  \n",
    "from sklearn.impute          import SimpleImputer\n",
    "from sklearn.metrics         import mean_squared_error, r2_score\n",
    "from tqdm                    import tqdm\n",
    "\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Ames Housing Dataset\n",
    "\n",
    "For a description of the features of this dataset, see the **Appendix**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/codespace/.cache/kagglehub/datasets/shashanknecrothapa/ames-housing-dataset/versions/1\n"
     ]
    }
   ],
   "source": [
    "# Download the latest version of the dataset\n",
    "path = kagglehub.dataset_download(\"shashanknecrothapa/ames-housing-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Construct the full path to the CSV file (update the file name if necessary)\n",
    "csv_file = os.path.join(path, \"AmesHousing.csv\")\n",
    "\n",
    "# Read the dataset into a DataFrame\n",
    "df = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order</th>\n",
       "      <th>PID</th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>MS Zoning</th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>Lot Shape</th>\n",
       "      <th>Land Contour</th>\n",
       "      <th>...</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Pool QC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>Misc Feature</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>Mo Sold</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>Sale Type</th>\n",
       "      <th>Sale Condition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>526301100</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>141.0</td>\n",
       "      <td>31770</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>526350040</td>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>526351010</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gar2</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>526353030</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>93.0</td>\n",
       "      <td>11160</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>244000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>527105010</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>189900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Order        PID  MS SubClass MS Zoning  Lot Frontage  Lot Area Street  \\\n",
       "0      1  526301100           20        RL         141.0     31770   Pave   \n",
       "1      2  526350040           20        RH          80.0     11622   Pave   \n",
       "2      3  526351010           20        RL          81.0     14267   Pave   \n",
       "3      4  526353030           20        RL          93.0     11160   Pave   \n",
       "4      5  527105010           60        RL          74.0     13830   Pave   \n",
       "\n",
       "  Alley Lot Shape Land Contour  ... Pool Area Pool QC  Fence Misc Feature  \\\n",
       "0   NaN       IR1          Lvl  ...         0     NaN    NaN          NaN   \n",
       "1   NaN       Reg          Lvl  ...         0     NaN  MnPrv          NaN   \n",
       "2   NaN       IR1          Lvl  ...         0     NaN    NaN         Gar2   \n",
       "3   NaN       Reg          Lvl  ...         0     NaN    NaN          NaN   \n",
       "4   NaN       IR1          Lvl  ...         0     NaN  MnPrv          NaN   \n",
       "\n",
       "  Misc Val Mo Sold Yr Sold Sale Type  Sale Condition  SalePrice  \n",
       "0        0       5    2010       WD           Normal     215000  \n",
       "1        0       6    2010       WD           Normal     105000  \n",
       "2    12500       6    2010       WD           Normal     172000  \n",
       "3        0       4    2010       WD           Normal     244000  \n",
       "4        0       3    2010       WD           Normal     189900  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first few rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 2930 entries, 0 to 2929\n",
      "Data columns (total 82 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Order            2930 non-null   int64  \n",
      " 1   PID              2930 non-null   int64  \n",
      " 2   MS SubClass      2930 non-null   int64  \n",
      " 3   MS Zoning        2930 non-null   str    \n",
      " 4   Lot Frontage     2440 non-null   float64\n",
      " 5   Lot Area         2930 non-null   int64  \n",
      " 6   Street           2930 non-null   str    \n",
      " 7   Alley            198 non-null    str    \n",
      " 8   Lot Shape        2930 non-null   str    \n",
      " 9   Land Contour     2930 non-null   str    \n",
      " 10  Utilities        2930 non-null   str    \n",
      " 11  Lot Config       2930 non-null   str    \n",
      " 12  Land Slope       2930 non-null   str    \n",
      " 13  Neighborhood     2930 non-null   str    \n",
      " 14  Condition 1      2930 non-null   str    \n",
      " 15  Condition 2      2930 non-null   str    \n",
      " 16  Bldg Type        2930 non-null   str    \n",
      " 17  House Style      2930 non-null   str    \n",
      " 18  Overall Qual     2930 non-null   int64  \n",
      " 19  Overall Cond     2930 non-null   int64  \n",
      " 20  Year Built       2930 non-null   int64  \n",
      " 21  Year Remod/Add   2930 non-null   int64  \n",
      " 22  Roof Style       2930 non-null   str    \n",
      " 23  Roof Matl        2930 non-null   str    \n",
      " 24  Exterior 1st     2930 non-null   str    \n",
      " 25  Exterior 2nd     2930 non-null   str    \n",
      " 26  Mas Vnr Type     1155 non-null   str    \n",
      " 27  Mas Vnr Area     2907 non-null   float64\n",
      " 28  Exter Qual       2930 non-null   str    \n",
      " 29  Exter Cond       2930 non-null   str    \n",
      " 30  Foundation       2930 non-null   str    \n",
      " 31  Bsmt Qual        2850 non-null   str    \n",
      " 32  Bsmt Cond        2850 non-null   str    \n",
      " 33  Bsmt Exposure    2847 non-null   str    \n",
      " 34  BsmtFin Type 1   2850 non-null   str    \n",
      " 35  BsmtFin SF 1     2929 non-null   float64\n",
      " 36  BsmtFin Type 2   2849 non-null   str    \n",
      " 37  BsmtFin SF 2     2929 non-null   float64\n",
      " 38  Bsmt Unf SF      2929 non-null   float64\n",
      " 39  Total Bsmt SF    2929 non-null   float64\n",
      " 40  Heating          2930 non-null   str    \n",
      " 41  Heating QC       2930 non-null   str    \n",
      " 42  Central Air      2930 non-null   str    \n",
      " 43  Electrical       2929 non-null   str    \n",
      " 44  1st Flr SF       2930 non-null   int64  \n",
      " 45  2nd Flr SF       2930 non-null   int64  \n",
      " 46  Low Qual Fin SF  2930 non-null   int64  \n",
      " 47  Gr Liv Area      2930 non-null   int64  \n",
      " 48  Bsmt Full Bath   2928 non-null   float64\n",
      " 49  Bsmt Half Bath   2928 non-null   float64\n",
      " 50  Full Bath        2930 non-null   int64  \n",
      " 51  Half Bath        2930 non-null   int64  \n",
      " 52  Bedroom AbvGr    2930 non-null   int64  \n",
      " 53  Kitchen AbvGr    2930 non-null   int64  \n",
      " 54  Kitchen Qual     2930 non-null   str    \n",
      " 55  TotRms AbvGrd    2930 non-null   int64  \n",
      " 56  Functional       2930 non-null   str    \n",
      " 57  Fireplaces       2930 non-null   int64  \n",
      " 58  Fireplace Qu     1508 non-null   str    \n",
      " 59  Garage Type      2773 non-null   str    \n",
      " 60  Garage Yr Blt    2771 non-null   float64\n",
      " 61  Garage Finish    2771 non-null   str    \n",
      " 62  Garage Cars      2929 non-null   float64\n",
      " 63  Garage Area      2929 non-null   float64\n",
      " 64  Garage Qual      2771 non-null   str    \n",
      " 65  Garage Cond      2771 non-null   str    \n",
      " 66  Paved Drive      2930 non-null   str    \n",
      " 67  Wood Deck SF     2930 non-null   int64  \n",
      " 68  Open Porch SF    2930 non-null   int64  \n",
      " 69  Enclosed Porch   2930 non-null   int64  \n",
      " 70  3Ssn Porch       2930 non-null   int64  \n",
      " 71  Screen Porch     2930 non-null   int64  \n",
      " 72  Pool Area        2930 non-null   int64  \n",
      " 73  Pool QC          13 non-null     str    \n",
      " 74  Fence            572 non-null    str    \n",
      " 75  Misc Feature     106 non-null    str    \n",
      " 76  Misc Val         2930 non-null   int64  \n",
      " 77  Mo Sold          2930 non-null   int64  \n",
      " 78  Yr Sold          2930 non-null   int64  \n",
      " 79  Sale Type        2930 non-null   str    \n",
      " 80  Sale Condition   2930 non-null   str    \n",
      " 81  SalePrice        2930 non-null   int64  \n",
      "dtypes: float64(11), int64(28), str(43)\n",
      "memory usage: 1.8 MB\n"
     ]
    }
   ],
   "source": [
    "# To see the listing of features\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Histograms\n"
     ]
    }
   ],
   "source": [
    "# To see the feature histograms\n",
    "\n",
    "print(\"Feature Histograms\")\n",
    "df.hist(figsize=(15, 13), bins=30)  # Adjust figure size and number of bins\n",
    "plt.tight_layout()  # Adjust spacing to prevent overlap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "First, let's remove the features that are clearly not useful for regression: the row-number `Order` and the Parcel Identification Number `PID`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>MS Zoning</th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>Lot Shape</th>\n",
       "      <th>Land Contour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>Lot Config</th>\n",
       "      <th>...</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Pool QC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>Misc Feature</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>Mo Sold</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>Sale Type</th>\n",
       "      <th>Sale Condition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>141.0</td>\n",
       "      <td>31770</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gar2</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>93.0</td>\n",
       "      <td>11160</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>244000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>189900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MS SubClass MS Zoning  Lot Frontage  Lot Area Street Alley Lot Shape  \\\n",
       "0           20        RL         141.0     31770   Pave   NaN       IR1   \n",
       "1           20        RH          80.0     11622   Pave   NaN       Reg   \n",
       "2           20        RL          81.0     14267   Pave   NaN       IR1   \n",
       "3           20        RL          93.0     11160   Pave   NaN       Reg   \n",
       "4           60        RL          74.0     13830   Pave   NaN       IR1   \n",
       "\n",
       "  Land Contour Utilities Lot Config  ... Pool Area Pool QC  Fence  \\\n",
       "0          Lvl    AllPub     Corner  ...         0     NaN    NaN   \n",
       "1          Lvl    AllPub     Inside  ...         0     NaN  MnPrv   \n",
       "2          Lvl    AllPub     Corner  ...         0     NaN    NaN   \n",
       "3          Lvl    AllPub     Corner  ...         0     NaN    NaN   \n",
       "4          Lvl    AllPub     Inside  ...         0     NaN  MnPrv   \n",
       "\n",
       "  Misc Feature Misc Val Mo Sold  Yr Sold  Sale Type  Sale Condition  SalePrice  \n",
       "0          NaN        0       5     2010        WD           Normal     215000  \n",
       "1          NaN        0       6     2010        WD           Normal     105000  \n",
       "2         Gar2    12500       6     2010        WD           Normal     172000  \n",
       "3          NaN        0       4     2010        WD           Normal     244000  \n",
       "4          NaN        0       3     2010        WD           Normal     189900  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = df.drop(columns=['Order','PID'])    # makes a copy\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem One: Dealing with Null Values\n",
    "\n",
    "There are basically two strategies for dealing with missing (null or `NaN`) values:\n",
    "- Get them out of your dataset by **removing** features and/or samples containing too many nulls.\n",
    "- **Impute** values by replacing nulls with the mean, median, or other \"neutral\" value computed from the feature.\n",
    "\n",
    "**Note:** It is also possible to impute values using more advanced techniques such as mode imputation, forward/backward fill, or predictive modeling (e.g., KNN or regression-based imputation). These more advanced techniques might be useful when you start to work on your project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First we will explore how many null values occur in each feature.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "def show_null_counts_features(df):\n",
    "    count_nulls = df.isnull().sum()\n",
    "    df_nulls = (df.isnull().mean() * 100).round(2)\n",
    "\n",
    "    feature_types = df.dtypes.apply(lambda x: 'Numeric' if is_numeric_dtype(x) else 'Categorical')\n",
    "\n",
    "    missing_data = pd.DataFrame({\n",
    "        'Feature': count_nulls[count_nulls > 0].index,\n",
    "        '# Null Values': count_nulls[count_nulls > 0].values,\n",
    "        'Null %': df_nulls[df_nulls > 0].values,\n",
    "        'Type': feature_types[count_nulls > 0].values\n",
    "    }).sort_values(by='Null %', ascending=False)\n",
    "\n",
    "    print(f'The dataset contains {len(df)} samples.\\n')\n",
    "\n",
    "    if len(missing_data) == 0:\n",
    "        print(\"There are no null values in the dataset!\")\n",
    "    else:\n",
    "        print('Feature Name    # Nulls      Null %    Type')\n",
    "        print('------------    -------      ------    ----')\n",
    "        for _, row in missing_data.iterrows():\n",
    "            print(f\"{row['Feature']:<15} {row['# Null Values']:<12} {row['Null %']:.2f}%   {row['Type']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A\n",
    "\n",
    "Clearly, some of these features are not very informative! Let's drop the worst offenders!\n",
    "\n",
    "**Fill in your code after the comments below to drop any features with more than `max_nulls` null values.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['df', 'df_clean', 'df_imputed']"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v for v in globals() if \"df\" in v.lower() or \"data\" in v.lower()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_nulls = 500      # we will drop any features with more than max_nulls missing values\n",
    "\n",
    "\n",
    "# Count null values per column\n",
    "null_counts = df.isnull().sum()\n",
    "\n",
    "# Filter out columns where null count exceeds max_nulls\n",
    "cols_to_drop = null_counts[null_counts > max_nulls].index\n",
    "\n",
    "# Drop the columns\n",
    "df_clean = df.drop(columns=cols_to_drop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graded Question\n",
    "\n",
    "Assign `a1a` to the number of features (columns) that were dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here; use an expression, not a constant derived by examining the data\n",
    "\n",
    "a1a = len(cols_to_drop)                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1a = 6\n"
     ]
    }
   ],
   "source": [
    "# Do not change this cell in any way\n",
    "\n",
    "print(f\"a1a = {a1a}\")                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B:  Feature Transformations for Imputing Null Values\n",
    "\n",
    "Now let's perform the following feature transformations:\n",
    "\n",
    "- For categorical features, we'll replace null values with the most frequent category in that column\n",
    "- For numeric features, we'll replace nulls with the median for that feature \n",
    "\n",
    "\n",
    "This is very simple to do with a couple of lines of Python, but naturally we want to use `sklearn` functions whenever we can, so we'll use ` SimpleImputer`.\n",
    "\n",
    "**Go read the doc page for `SimpleImputer` before proceeding.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing Categorical Features using the Most Frequent Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell you see how easy it is to examine the categories. **Take a moment and explore several of the categorical features.**  In this dataset, most of them are skewed, with a clear \"most favorite\" category. \n",
    "(If the feature values are not skewed, then you could change these to a new category \"Unknown\".)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Garage Qual\n",
       "TA     2615\n",
       "NaN     159\n",
       "Fa      124\n",
       "Gd       24\n",
       "Po        5\n",
       "Ex        3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['Garage Qual'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding, let's get lists of the two types of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical and numeric features\n",
    "\n",
    "categorical_features = df_clean.select_dtypes(exclude=['number']).columns.tolist()\n",
    "numeric_features     = df_clean.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "# Uncomment to print results\n",
    "\n",
    "# print(\"Categorical Features:\", categorical_features)\n",
    "# print()\n",
    "# print(\"Numeric Features:\", numeric_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now you must impute all the categorical features using `SimpleImputer` with the `most_frequent` strategy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy so we don't overwrite df_clean\n",
    "df_imputed = df_clean.copy()\n",
    "\n",
    "# Impute categorical features with the most frequent value\n",
    "cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "df_imputed[categorical_features] = cat_imputer.fit_transform(df_imputed[categorical_features])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graded Question\n",
    "\n",
    "Set `a1b` to the number of occurrences of the category `TA` in the feature `Garage Qual`. \n",
    "It should have increased from before the imputation, because `NaN` values were changed to `TA`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here; use an expression, not a constant derived by examining the data\n",
    "\n",
    "a1b = (df_imputed[\"Garage Qual\"] == \"TA\").sum()               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1b = 2774\n"
     ]
    }
   ],
   "source": [
    "# Do not change this cell in any way\n",
    "\n",
    "print(f\"a1b = {a1b}\")                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C:  Imputing Numeric Features using the Median\n",
    "\n",
    "Now you must \"simply impute\" values for the missing numeric features using the `median` strategy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import is_numeric_dtype\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Copy clean dataframe\n",
    "df_imputed = df_clean.copy()\n",
    "\n",
    "# Select numeric columns\n",
    "numeric_cols = df_imputed.select_dtypes(include=np.number).columns\n",
    "\n",
    "# Create median imputer\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Apply imputer\n",
    "df_imputed[numeric_cols] = imputer.fit_transform(df_imputed[numeric_cols])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graded Question\n",
    "\n",
    "Set `a1c` to the number of rows with missing values.  Use an expression, not a constant derived by examining the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here; use an expression, not a constant derived by examining the data\n",
    "\n",
    "a1c = df_imputed.isnull().any(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1c = 230\n"
     ]
    }
   ],
   "source": [
    "# Do not change this cell in any way\n",
    "\n",
    "print(f\"a1c = {a1c}\")                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part D:   Ordinal Encoding the categorical features with OrdinalEncoder\n",
    "\n",
    "The simplest option in dealing with categorical values is to represent them by integers 0, 1, 2, etc.\n",
    "\n",
    "**Before proceeding, read the doc page on `sklearn`'s `OrdinalEncoder`.**\n",
    "\n",
    "> **Note on categorical encoding**\n",
    "> We use OrdinalEncoder here as a simple, uniform approach to handling categorical variables. Some of these\n",
    "> features are truly ordinal (e.g., quality and condition ratings), while others are nominal (no implied\n",
    "> ordering among values). Ordinal encoding is not ideal for nominal variables, but it provides a compact\n",
    "> baseline representation suitable for this assignment. We may need to consider alternative encodings\n",
    "> later in the course.\n",
    "\n",
    "\n",
    "Follow the comments to perform this feature transformation.\n",
    "\n",
    "#### Note: Do not simply apply the `OrdinalEncoder` to the entire dataframe, as it will also encode the numeric features!\n",
    "#### You can solve this using the same approach as the transformation in the previous problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put df_imputed in the form X, y\n",
    "X = df_imputed.drop(\"SalePrice\", axis=1)\n",
    "y = df_imputed[\"SalePrice\"]\n",
    "\n",
    "# Identify categorical columns\n",
    "cat_cols = X.select_dtypes(include=[\"object\", \"string\", \"category\"]).columns\n",
    "num_cols = X.select_dtypes(exclude=[\"object\", \"string\", \"category\"]).columns\n",
    "\n",
    "# Initialize OrdinalEncoder\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "# Fit + transform categorical features\n",
    "X_cat_encoded = encoder.fit_transform(X[cat_cols])\n",
    "\n",
    "# Convert back to DataFrame\n",
    "X_cat_encoded = pd.DataFrame(\n",
    "    X_cat_encoded,\n",
    "    columns=cat_cols,\n",
    "    index=X.index\n",
    ")\n",
    "\n",
    "# Combine numeric + encoded categorical\n",
    "X = pd.concat([X[num_cols], X_cat_encoded], axis=1)\n",
    "\n",
    "# Ensure everything is float64\n",
    "X = X.astype(\"float64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graded Question\n",
    "\n",
    "Set `a1d` to the number of categories imputed for `Lot Shape`. Hint: Just take the `len(...)` of the unique values in the newly-computed feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here; use an expression, not a constant derived by examining the data\n",
    "\n",
    "a1d = len(X[\"Lot Shape\"].unique())                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1d = 4\n"
     ]
    }
   ],
   "source": [
    "# Do not change this cell in any way\n",
    "\n",
    "print(f\"a1d = {a1d}\")                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Two:  Train and Test a Regression Model with Cross-Validation and Root Mean Square Errors\n",
    "\n",
    "In this problem, we will perform a regression on the Ames Housing Dataset using several different cross-validation\n",
    "strategies, comparing the cross-validation score for each with the final testing score, to see which provides the best\n",
    "estimate of the final test score, and hence of the model's ability to generalize. \n",
    "\n",
    "\n",
    "We shall compare each of the following cross-validation RMSEs with the final test RMSE score:\n",
    "\n",
    "- 5-Fold Cross-Validation (default)\n",
    "- Repeated 5-Fold Cross-Validation (repeated 100 times)\n",
    "- Leave-One-Out Cross Validation\n",
    "\n",
    "> **Note:**\n",
    "> `cross_val_score` always returns a score that is maximized.\n",
    "> \n",
    "> For regression models, the default score is $R^2$, so values may be positive even though no error metric was specified.\n",
    "> \n",
    "> For error metrics such as root mean squared error (RMSE), scikit-learn provides already-negated scorers (e.g., `scoring='neg_root_mean_squared_error'`).\n",
    "These return −RMSE and must be negated to recover the RMSE on its original scale.\n",
    "> \n",
    "> Be careful not to compare scores computed using different metrics (e.g., $R^2$ vs. RMSE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A: 5-Fold Cross-Validation\n",
    "\n",
    "For this part\n",
    "- Create a train-test split with `test_size=0.2` and `random_state=random_seed`\n",
    "- Create a linear model and perform K-fold cross-validation with K = 5 and using `scoring='neg_root_mean_squared_error'` (remember to take the mean of the CV scores and negate the result, since results are negative). \n",
    "- Report the\n",
    "    - CV score (negated mean of RMSE measurements over all K folds)\n",
    "    - Test RMSE\n",
    "\n",
    "\n",
    "Use `random_state = random_seed` for all experiments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in X: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9252/4165458550.py:25: Pandas4Warning: For backward compatibility, 'str' dtypes are included by select_dtypes when 'object' dtype is specified. This behavior is deprecated and will be removed in a future version. Explicitly pass 'str' to `include` to select them, or to `exclude` to remove them and silence this warning.\n",
      "See https://pandas.pydata.org/docs/user_guide/migration-3-strings.html#string-migration-select-dtypes for details on how to write code that works with pandas 2 and 3.\n",
      "  if X_raw.select_dtypes(include=\"object\").shape[1] > 0:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(34993.367311419024), np.float64(29098.662509374517))"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "target = \"SalePrice\"\n",
    "\n",
    "# y always comes from original df\n",
    "y = df[target]\n",
    "\n",
    "# X should come from your encoded dataframe IF it exists,\n",
    "# otherwise fall back to df and force everything numeric\n",
    "# (this avoids the \"df_encoded not defined\" issue)\n",
    "if \"df_encoded\" in globals():\n",
    "    X_raw = df_encoded.drop(columns=[target], errors=\"ignore\").copy()\n",
    "elif \"df_imputed\" in globals():\n",
    "    X_raw = df_imputed.drop(columns=[target], errors=\"ignore\").copy()\n",
    "else:\n",
    "    X_raw = df.drop(columns=[target]).copy()\n",
    "\n",
    "# Make sure everything is numeric (if any object columns exist, one-hot them)\n",
    "if X_raw.select_dtypes(include=\"object\").shape[1] > 0:\n",
    "    X_raw = pd.get_dummies(X_raw, drop_first=True)\n",
    "\n",
    "# Impute remaining NaNs (median for numeric)\n",
    "imp = SimpleImputer(strategy=\"median\")\n",
    "X = pd.DataFrame(imp.fit_transform(X_raw), columns=X_raw.columns)\n",
    "\n",
    "# sanity check\n",
    "print(\"NaNs in X:\", np.isnan(X.to_numpy()).sum())\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=random_seed\n",
    ")\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "# 5-fold CV RMSE\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=random_seed)\n",
    "cv_scores = cross_val_score(\n",
    "    model, X_train, y_train,\n",
    "    cv=cv,\n",
    "    scoring=\"neg_root_mean_squared_error\"\n",
    ")\n",
    "cv_rmse_5fold = -cv_scores.mean()\n",
    "\n",
    "# Fit + test RMSE (manual sqrt to avoid squared=False issues)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "cv_rmse_5fold, test_rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order           float64\n",
      "PID             float64\n",
      "MS SubClass     float64\n",
      "Lot Frontage    float64\n",
      "Lot Area        float64\n",
      "dtype: object\n",
      "NaNs in X: 0\n"
     ]
    }
   ],
   "source": [
    "# Use the encoded X from Part D (should already be numeric)\n",
    "# and y from the original df\n",
    "target = \"SalePrice\"\n",
    "\n",
    "y = df[target]\n",
    "# X should already exist from Part D; just verify it's numeric\n",
    "print(X.dtypes.head())\n",
    "print(\"NaNs in X:\", X.isna().sum().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graded Question\n",
    "\n",
    "Set `a2a` to the Test RMSE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here; use an expression, not a constant derived by examining the data\n",
    "\n",
    "a2a =  test_rmse                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2a = $29,098.66\n"
     ]
    }
   ],
   "source": [
    "# Do not change this cell in any way\n",
    "\n",
    "print(f\"a2a = ${a2a:,.2f}\")                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B: Perform Repeated 5-Fold Cross Validation\n",
    "\n",
    "Read the doc page on `sklearn`'s `RepeatedKFold` for cross validation; repeat the CV calculation with K = 5 and `n_repeats=100`\n",
    "and report the CV score (negated mean of RMSE measurements over all 100*K folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(35385.81551490446)"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=100, random_state=random_seed)\n",
    "rep_scores = cross_val_score(\n",
    "    model, X_train, y_train,\n",
    "    cv=rkf,\n",
    "    scoring=\"neg_root_mean_squared_error\"\n",
    ")\n",
    "cv_rmse_repeated = -rep_scores.mean()\n",
    "cv_rmse_repeated\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graded Question\n",
    "\n",
    "Set `a2b` to the mean CV score for the repeated K-fold experiment.\n",
    "\n",
    "Note: if your CV score is negative, go back and read the instructions for Part A again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here; use an expression, not a constant derived by examining the data\n",
    "\n",
    "a2b = cv_rmse_repeated                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2b = $35,385.82\n"
     ]
    }
   ],
   "source": [
    "# Do not change this cell in any way\n",
    "\n",
    "print(f\"a2b = ${a2b:,.2f}\")                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C: Perform Leave One Out Cross Validation\n",
    "\n",
    "This is simply a matter of setting `cv=LeaveOneOut()`. Run the same experiment and report the CV score. \n",
    "\n",
    "**Note:** It may take 10 or more minutes to run.  Be patient (a good skill for an ML engineer to develop!). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(16917.077160133187)"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "loo_scores = cross_val_score(\n",
    "    model, X_train, y_train,\n",
    "    cv=loo,\n",
    "    scoring=\"neg_root_mean_squared_error\"\n",
    ")\n",
    "cv_rmse_loo = -loo_scores.mean()\n",
    "cv_rmse_loo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graded Question\n",
    "\n",
    "Set `a2c` to the mean CV score for the leave-one-out experiment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here; use an expression, not a constant derived by examining the data\n",
    "\n",
    "a2c = cv_rmse_loo                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2c = $16,917.08\n"
     ]
    }
   ],
   "source": [
    "# Do not change this cell in any way\n",
    "\n",
    "print(f\"a2c = ${a2c:,.2f}\")                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part D: Which method gives the best estimate of generalization?\n",
    "\n",
    "Different cross-validation strategies use the available data in different ways.\n",
    "Although all of them aim to estimate how well a model will perform on unseen data,\n",
    "their estimates can differ due to bias, variance, and how the data are split.\n",
    "\n",
    "In this part, we compare the different cross-validation strategies to the held-out **test**\n",
    "set to see which one provides the closest estimate of the model’s true\n",
    "generalization performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graded Question\n",
    "\n",
    "Set `a2d` to the **number** of the strategy whose cross-validation RMSE is closest (in absolute difference) to the Test RMSE, and hence potentially provides the best estimate of generalization performance.\n",
    "\n",
    "Use:\n",
    "- 1 = 5-fold CV\n",
    "- 2 = Repeated 5-Fold CV\n",
    "- 3 = Leave-One-Out CV\n",
    "\n",
    "If two strategies are very close, you may choose either. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a2d = int(np.argmin([\n",
    "    abs(cv_rmse_5fold - test_rmse),\n",
    "    abs(cv_rmse_repeated - test_rmse),\n",
    "    abs(cv_rmse_loo - test_rmse),\n",
    "]) + 1)                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2d = 1\n"
     ]
    }
   ],
   "source": [
    "# Do not change this cell in any way\n",
    "\n",
    "print(f\"a2d = {a2d}\")                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional Problem\n",
    "\n",
    "Repeat the K-Fold and Repeated K-Fold experiments you just did in Problem 2, but use the $R^2$ metric (the default for `cross_validation_score` and does not need to be negated). (LOO can't use R2.) Did you get the same result for the last part (D)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Explanation of Features in Ames Housing Dataset\n",
    "\n",
    "### **Identification**\n",
    "- `PID` → Parcel Identification Number (unique identifier for each property)\n",
    "- `Order` → Row number (used for indexing, not a feature)\n",
    "\n",
    "---\n",
    "\n",
    "### **Sale Information**\n",
    "- `SalePrice` → The final selling price of the house in USD (**Target variable**)\n",
    "- `Mo Sold` → Month the house was sold (1 = January, ..., 12 = December)\n",
    "- `Yr Sold` → Year the house was sold\n",
    "- `Sale Type` → Type of sale (e.g., **WD** = Warranty Deed, **New** = Newly Built)\n",
    "- `Sale Condition` → Condition of the sale (e.g., **Normal**, **Abnormal**, **Partial** for incomplete homes)\n",
    "\n",
    "---\n",
    "\n",
    "### **General Property Information**\n",
    "- `MS SubClass` → Type of dwelling (e.g., **20 = 1-story**, **60 = 2-story**, **120 = Townhouse**)\n",
    "- `MS Zoning` → Zoning classification (e.g., **RL = Residential Low Density**, **C = Commercial**)\n",
    "- `Lot Frontage` → Linear feet of street connected to property\n",
    "- `Lot Area` → Total size of the lot in square feet\n",
    "- `Neighborhood` → Physical locations within Ames (e.g., **CollgCr = College Creek**)\n",
    "- `Condition 1` / `Condition 2` → Proximity to roads or railroads (e.g., **Norm = Normal**, **PosN = Near Park**)\n",
    "\n",
    "---\n",
    "\n",
    "### **Building & House Design**\n",
    "- `Bldg Type` → Type of dwelling (e.g., **1Fam = Single Family**, **Twnhs = Townhouse**)\n",
    "- `House Style` → Style of the house (e.g., **1Story = One Story**, **2Story = Two Story**, **SplitFoyer**)\n",
    "- `Overall Qual` → Overall quality of materials (scale: **1 = Very Poor** to **10 = Excellent**)\n",
    "- `Overall Cond` → Overall condition of the house (scale: **1 = Very Poor** to **10 = Excellent**)\n",
    "\n",
    "---\n",
    "\n",
    "### **Year Built & Remodel**\n",
    "- `Year Built` → Original construction year\n",
    "- `Year Remod/Add` → Year of last remodel or addition\n",
    "\n",
    "---\n",
    "\n",
    "### **Exterior Features**\n",
    "- `Exterior 1st` / `Exterior 2nd` → Exterior covering material (e.g., **VinylSd = Vinyl Siding**, **HdBoard = Hardboard**)\n",
    "- `Mas Vnr Type` → Masonry veneer type (e.g., **BrkFace = Brick Face**, **None = No Veneer**)\n",
    "- `Mas Vnr Area` → Area of masonry veneer in square feet\n",
    "\n",
    "---\n",
    "\n",
    "### **Basement Features**\n",
    "- `Bsmt Qual` → Basement height (e.g., **Ex = Excellent**, **TA = Typical**, **Po = Poor**)\n",
    "- `Bsmt Cond` → General condition of the basement\n",
    "- `Bsmt Exposure` → Walkout or garden level basement?\n",
    "- `BsmtFin Type 1` / `BsmtFin SF 1` → Primary finished area in basement (e.g., **GLQ = Good Living Quarters**)\n",
    "- `BsmtFin Type 2` / `BsmtFin SF 2` → Secondary finished area\n",
    "- `Bsmt Unf SF` → Unfinished square feet in basement\n",
    "- `Total Bsmt SF` → Total square footage of basement\n",
    "\n",
    "---\n",
    "\n",
    "### **Utilities & HVAC**\n",
    "- `Heating` → Type of heating system (e.g., **GasA = Gas Forced Air**, **OthW = Hot Water Heating**)\n",
    "- `Heating QC` → Quality of heating system (e.g., **Ex = Excellent**, **Fa = Fair**)\n",
    "- `Central Air` → **Y = Yes**, **N = No**\n",
    "- `Electrical` → Electrical system (e.g., **SBrkr = Standard Breaker**, **FuseA = Fuse Box**)\n",
    "\n",
    "---\n",
    "\n",
    "### **Above Ground Living Area**\n",
    "- `1st Flr SF` → First-floor square footage\n",
    "- `2nd Flr SF` → Second-floor square footage\n",
    "- `Gr Liv Area` → Total **above-ground** living area in square feet\n",
    "- `Low Qual Fin SF` → Low-quality finished square feet (e.g., unfinished rooms)\n",
    "\n",
    "---\n",
    "\n",
    "### **Bathrooms & Bedrooms**\n",
    "- `Full Bath` → Full bathrooms above ground\n",
    "- `Half Bath` → Half bathrooms above ground\n",
    "- `Bsmt Full Bath` → Full bathrooms in basement\n",
    "- `Bsmt Half Bath` → Half bathrooms in basement\n",
    "- `Bedroom AbvGr` → Number of bedrooms above ground\n",
    "- `Kitchen AbvGr` → Number of kitchens above ground\n",
    "- `Kitchen Qual` → Kitchen quality (**Ex = Excellent**, **Fa = Fair**)\n",
    "\n",
    "---\n",
    "\n",
    "### **Garage Features**\n",
    "- `Garage Type` → Type of garage (e.g., **Attchd = Attached**, **Detchd = Detached**)\n",
    "- `Garage Yr Blt` → Year garage was built\n",
    "- `Garage Finish` → Interior finish of garage\n",
    "- `Garage Cars` → Size of garage in car capacity\n",
    "- `Garage Area` → Garage size in square feet\n",
    "\n",
    "---\n",
    "\n",
    "### **Additional Features**\n",
    "- `Fireplaces` → Number of fireplaces\n",
    "- `Fireplace Qu` → Fireplace quality\n",
    "- `Paved Drive` → Paved driveway? (**Y = Yes, P = Partial, N = No**)\n",
    "- `Wood Deck SF` → Square footage of wood deck\n",
    "- `Open Porch SF` → Square footage of open porch\n",
    "- `Enclosed Porch` → Square footage of enclosed porch\n",
    "- `Screen Porch` → Square footage of screened porch\n",
    "- `Pool Area` → Pool area in square feet\n",
    "- `Misc Val` → Miscellaneous features (e.g., shed value)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
